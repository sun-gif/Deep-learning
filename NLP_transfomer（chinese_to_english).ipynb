{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-transfomerï¼ˆchinese to english).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghk_rezDFoKy"
      },
      "source": [
        "!pip uninstall spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-bjhS_6F7hh"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg_0AeTmuWPM"
      },
      "source": [
        "\n",
        "import torch\n",
        "import spacy\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import sys\n",
        "\n",
        "\n",
        "def translate_sentence(model, sentence, chinese, english, device, max_length=50):\n",
        "    # Load german tokenizer\n",
        "    spacy_che = spacy.load(\"zh_core_web_sm\")\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_che(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, chinese.init_token)\n",
        "    tokens.append(chinese.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [chinese.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(sentence_tensor, trg_tensor)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    # remove start token\n",
        "    return translated_sentence[1:]\n",
        "\n",
        "\n",
        "def bleu(data, model, chinese, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"che\"]\n",
        "        trg = vars(example)[\"eng\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, chinese, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdT6oDkeulO6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "\n",
        "import torchtext\n",
        "#from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator,TabularDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "XAAKIIctpE4K",
        "outputId": "ca3d1502-018b-489a-9822-1c99ef1b04f5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b9011ff0-00a0-457e-be53-978a3d5ed9e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b9011ff0-00a0-457e-be53-978a3d5ed9e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cmn.txt to cmn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohQymdAmwJPL"
      },
      "source": [
        "import numpy as np\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mon9h9_s0QbJ",
        "outputId": "89ad6e2e-18f2-46ff-ded6-0807cb46d015"
      },
      "source": [
        "import pandas as pd\n",
        "file_name='cmn.txt'\n",
        "lines = uploaded[file_name].decode(\"utf-8\").split(\"\\n\")\n",
        "pairs=[line.split('\\t')[:2] for line in lines]\n",
        "df=pd.DataFrame(pairs[:20000],columns=['english','chinese'])\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ9ndiElx7G1"
      },
      "source": [
        "# create train and test set\n",
        "train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# Get train, test data to json and csv format which can be read by torchtext\n",
        "train.to_json(\"train.json\", orient=\"records\", lines=True)\n",
        "test.to_json(\"test.json\", orient=\"records\", lines=True)\n",
        "\n",
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZKpz6mFvohD"
      },
      "source": [
        "\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download zh_core_web_sm\n",
        "\n",
        "spacy_che = spacy.load(\"zh_core_web_sm\")\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "def tokenize_che(text):\n",
        "    return [tok.text for tok in spacy_che.tokenizer(text)]\n",
        "\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "\n",
        "chinese = Field(tokenize=tokenize_che, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(\n",
        "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
        ")\n",
        "\n",
        "#train_data, valid_data, test_data = pairs.splits(\n",
        "#    exts=(\".ch\", \".en\"), fields=(chinese, english)\n",
        "#)\n",
        "\n",
        "#chinese.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "#english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3wgsgxiydkj",
        "outputId": "e2a8df60-53c7-45af-e374-fbc7d37d7608"
      },
      "source": [
        "fields = {'english': (\"eng\", english),'chinese': (\"che\", chinese)}\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(\n",
        "    path=\"\", train=\"train.json\", test=\"test.json\", format=\"json\", fields=fields\n",
        ")\n",
        "\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "chinese.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "train_iterator,  test_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.che),\n",
        "   \n",
        "    device=device,\n",
        ")\n",
        "\n",
        "\n",
        "for batch in train_iterator:\n",
        "    print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 18x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 18x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 18x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 15x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 15x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 19x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 16x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 15x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 12x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 17x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 10x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 5x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 14x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 13x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 8x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 6x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 9x32 (GPU 0)]\n",
            "\n",
            "[torchtext.legacy.data.batch.Batch of size 32]\n",
            "\t[.eng]:[torch.cuda.LongTensor of size 11x32 (GPU 0)]\n",
            "\t[.che]:[torch.cuda.LongTensor of size 7x32 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8MG4p9BmqxO"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WhPFl97wPyq"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "        # (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7v4dxOUKBaq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc3zzccEwiJi"
      },
      "source": [
        "\n",
        "# We're ready to define everything we need for training our Seq2Seq model\n",
        "\n",
        "\n",
        "load_model = True\n",
        "save_model = True\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 200\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Model hyperparameters\n",
        "src_vocab_size = len(chinese.vocab)\n",
        "trg_vocab_size = len(english.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 100\n",
        "forward_expansion = 4\n",
        "src_pad_idx = chinese.vocab.stoi[\"<pad>\"]\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(\"runs/loss_plot\")\n",
        "step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go-3ilaUwoPN"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmbRlK2wub4h",
        "outputId": "9c3f593e-7521-4f6b-9af6-1d4902cfca7f"
      },
      "source": [
        "\n",
        "\n",
        "sentence = \"æ˜Žå¤©ä¼šæ›´å¥½\"\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    if save_model:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "    translated_sentence = translate_sentence(\n",
        "        model, sentence, chinese, english, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.che.to(device)\n",
        "        target = batch.eng.to(device)\n",
        "       \n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target[:-1])\n",
        "\n",
        "       \n",
        "     \n",
        "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "        # way that we have output_words * batch_size that we want to send in into\n",
        "        # our cost function, so we need to do some reshapin.\n",
        "        # Let's also remove the start token while we're at it\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "      \n",
        "        target = target[1:].reshape(-1)\n",
        "        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # plot to tensorboard\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "    scheduler.step(mean_loss)\n",
        "\n",
        "# running on entire test data takes a while\n",
        "score = bleu(test_data[1:100], model, chinese, english, device)\n",
        "print(f\"Bleu score {score * 100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 1 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'it', \"'s\", 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 2 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 3 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 4 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'it', \"'s\", 'going', 'to', 'be', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 5 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'i', \"'ll\", 'be', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 6 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'you', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 7 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'will', 'come', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 8 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 9 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'better', 'than', 'i', 'do', '.', '<eos>']\n",
            "[Epoch 10 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'come', '.', '<eos>']\n",
            "[Epoch 11 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 12 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'play', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 13 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 14 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'anyone', '.', '<eos>']\n",
            "[Epoch 15 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 16 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'you', '.', '<eos>']\n",
            "[Epoch 17 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'better', 'can', 'come', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 18 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'more', 'will', 'come', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 19 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'i', 'will', 'be', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 20 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'come', '.', '<eos>']\n",
            "[Epoch 21 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'nothing', '.', '<eos>']\n",
            "[Epoch 22 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 23 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'get', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 24 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 25 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 26 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['could', 'come', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 27 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 28 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 29 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', '.', '<eos>']\n",
            "[Epoch 30 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'it', \"'s\", 'going', 'to', 'be', 'better', '.', '<eos>']\n",
            "[Epoch 31 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'is', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 32 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 33 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 34 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 35 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 36 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 37 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'ready', '.', '<eos>']\n",
            "[Epoch 38 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 39 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'it', '.', '<eos>']\n",
            "[Epoch 40 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 41 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 42 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 43 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 44 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'it', \"'s\", 'going', 'to', 'be', 'fine', '.', '<eos>']\n",
            "[Epoch 45 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 46 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'it', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 47 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['see', 'you', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 48 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 49 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 50 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 51 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 52 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 53 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['we', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 54 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 55 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 56 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', \"'s\", 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 57 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'m\", 'going', 'to', 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 58 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 59 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 60 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'m\", 'going', 'to', 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 61 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 62 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'ready', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 63 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 64 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['see', 'you', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 65 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 66 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 67 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'is', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 68 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', \"'s\", 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 69 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 70 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'can', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 71 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 72 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'able', 'to', 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 73 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 74 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'be', 'nice', 'day', '.', '<eos>']\n",
            "[Epoch 75 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 76 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'can', 'cook', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 77 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['we', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 78 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['we', 'can', 'speak', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 79 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'come', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 80 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'be', 'ready', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 81 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 82 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 83 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 84 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 85 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 86 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 87 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 88 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 89 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['we', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 90 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 91 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 92 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 93 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 94 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 95 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 96 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 97 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 98 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 99 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 100 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 101 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 102 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 103 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['do', 'you', 'have', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 104 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 105 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'ready', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 106 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 107 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 108 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 109 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 110 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 111 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'come', 'again', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 112 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', ',', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 113 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', \"'s\", 'getting', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 114 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'come', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 115 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 116 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'is', 'likely', 'to', 'be', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 117 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 118 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 119 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 120 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 121 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 122 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', \"'s\", 'going', 'to', 'be', 'more', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 123 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 124 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 125 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 126 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'german', '.', '<eos>']\n",
            "[Epoch 127 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 128 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'know', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 129 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', '.', '<eos>']\n",
            "[Epoch 130 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'come', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 131 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 132 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 133 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', '.', '<eos>']\n",
            "[Epoch 134 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', '.', '<eos>']\n",
            "[Epoch 135 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 136 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'be', 'more', 'pretty', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 137 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 138 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 139 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 140 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 141 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 142 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 143 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 144 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 145 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['do', \"n't\", 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 146 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 147 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 148 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 149 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['the', 'medicine', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 150 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'you', 'tomorrow', \"'s\", 'weather', '.', '<eos>']\n",
            "[Epoch 151 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 152 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 153 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'get', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 154 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', '.', '<eos>']\n",
            "[Epoch 155 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 156 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 157 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 158 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 159 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'it', 'will', 'be', 'more', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 160 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 161 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'anyone', '.', '<eos>']\n",
            "[Epoch 162 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'six', '.', '<eos>']\n",
            "[Epoch 163 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'get', 'better', '.', '<eos>']\n",
            "[Epoch 164 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', '.', '<eos>']\n",
            "[Epoch 165 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 166 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['the', 'police', 'will', 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 167 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', \"'s\", 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 168 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 169 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 170 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'you', '.', '<eos>']\n",
            "[Epoch 171 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'nothing', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 172 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'nothing', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 173 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 174 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 175 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'nice', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 176 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 177 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'going', 'to', 'be', 'fine', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 178 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'ok', '.', '<eos>']\n",
            "[Epoch 179 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'german', '.', '<eos>']\n",
            "[Epoch 180 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'ok', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 181 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'be', 'ok', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 182 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 183 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 184 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 185 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', '.', '<eos>']\n",
            "[Epoch 186 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['it', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 187 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'nothing', '.', '<eos>']\n",
            "[Epoch 188 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'can', 'play', 'basketball', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 189 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['i', \"'ll\", 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 190 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'you', 'have', 'been', 'quite', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 191 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'weather', '.', '<eos>']\n",
            "[Epoch 192 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', 'nothing', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 193 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'you', 'send', 'today', '.', '<eos>']\n",
            "[Epoch 194 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'than', '<eos>']\n",
            "[Epoch 195 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'come', 'tomorrow', 'better', '.', '<eos>']\n",
            "[Epoch 196 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'is', 'better', 'today', '.', '<eos>']\n",
            "[Epoch 197 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['tomorrow', 'will', 'be', 'better', 'tomorrow', '.', '<eos>']\n",
            "[Epoch 198 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'you', 'send', 'today', '.', '<eos>']\n",
            "[Epoch 199 / 200]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['will', 'you', 'send', 'today', '.', '<eos>']\n",
            "Bleu score 21.47\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}